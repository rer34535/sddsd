import fs from 'fs/promises';
import path from 'path';
import { OpenAI } from 'openai';
import * as predictionsData from '../../../predictionsData.js';

const openrouterApiKey = process.env.OPENROUTER_API_KEY;

// Helper function to get the project root directory
const getProjectRoot = () => {
    // In Netlify functions, the CWD is the root of the project.
    return process.cwd();
};

export async function handler(event, context) {
    if (event.httpMethod !== 'POST') {
        return {
            statusCode: 405,
            body: JSON.stringify({ error: 'Method Not Allowed' })
        };
    }

    try {
        const body = JSON.parse(event.body);
        const { type, analysisType, inputData, apiKey } = body;

        const finalApiKey = apiKey || openrouterApiKey;

        if (!finalApiKey) {
            return {
                statusCode: 400,
                body: JSON.stringify({ error: 'API key is required.' })
            };
        }

        const openai = new OpenAI({
            baseURL: "https://openrouter.ai/api/v1",
            apiKey: finalApiKey,
        });

        const projectRoot = getProjectRoot();
        const promptTemplatePath = path.join(projectRoot, 'ai_analysis_prompt.md');
        const promptTemplate = await fs.readFile(promptTemplatePath, 'utf-8');

        let knowledgeBase = '';
        const dataType = type === 'Ø´Ø®Øµ' ? predictionsData.gufrPersonPredictions : predictionsData.gufrPredictions;
        const analysisTimeframe = analysisType ? analysisType.toLowerCase() : 'general';

        if (dataType && dataType[analysisTimeframe]) {
            knowledgeBase = `\n\nğŸ”® Ø§Ø³ØªØ®Ø¯Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„ØªØ§Ù„ÙŠØ© ÙƒÙ…ØµØ¯Ø± Ø£Ø³Ø§Ø³ÙŠ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„. ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n\n${JSON.stringify(dataType[analysisTimeframe], null, 2)}`;
        }

        const finalPrompt = `${promptTemplate}\n\n${knowledgeBase}\n\nâœ… Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠ:\n\n${inputData}`;

        const completion = await openai.chat.completions.create({
            model: 'google/gemini-pro',
            messages: [{ role: 'user', content: finalPrompt }],
        });

        const result = completion.choices[0]?.message?.content;

        if (!result) {
            throw new Error('No result from AI model');
        }

        return {
            statusCode: 200,
            body: JSON.stringify({ result })
        };

    } catch (error) {
        console.error('Error during AI analysis:', error);
        return {
            statusCode: 500,
            body: JSON.stringify({ error: 'An error occurred during AI analysis.', details: error.message })
        };
    }
}
